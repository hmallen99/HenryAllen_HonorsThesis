\documentclass[../main.tex]{subfiles}

\begin{document}
Detecting the orientation of contrast edges is a fundamental function in the visual cortex \citep{hubel_wiesel_1959, hubel_wiesel_1968}. In the past twenty years, research has shown that the orientation of a stimulus can be decoded from the human brain using MEG and fMRI \citep{haynes_rees_2005, kamitani_tong_2005, mannion_mcdonald_clifford_2009, cichy_ramirez_pantazis_2015}. However, recent experiments in visual serial dependence have shown that the perception of stimulus orientation is serially dependent: the perception of the current stimulus is biased towards the orientation of the previous stimulus \citep{fischer_whitney_2014}. Visual serial dependence suggests that the orientation perception of the current stimulus is biased towards the orientation of the previous stimulus. To what extent are orientation decoding models affected by stimulus history? Here, we investigated the impact of previous stimuli on orientation decoding with MEG.

\subsection*{Orientation}
Orientation is a well understood mechanism in the visual cortex, thanks largely to the works of Hubel and Wiesel. Hubel and Wiesel first discovered cells in the visual cortex that were sensitive to orientation in 1958, when measuring the excitation of neurons in the cat primary visual cortex \citep{hubel_wiesel_1959}. \cite{hubel_wiesel_1962} then revealed the existence of simple and complex receptive fields in the cat visual cortex, both maximally sensitive to a particular orientation. Simple cells have very narrow excitatory receptive fields in which they respond to a single orientation at a single spatial location. These excitatory regions are surrounded by inhibitory regions, which generate inhibitory responses when aligned with the correct orientation. Complex cells have much wider excitatory receptive fields, as they take in inputs from multiple simple cells tuned to a certain orientation in a spatial region. \cite{hubel_wiesel_1968} further revealed the existence of slabs in the primary visual cortex of a macaque and spider monkey that were made up of these simple and complex cells, each tuned to a small range of orientations. Later work revealed that simple cells were not bar detectors, as Hubel and Weisel supposed, but spatial frequency detectors \citep{DEVALOIS1982545, devalois_1978}. 

Orientation columns are organized around loci called pinwheels, and orientation selectivity continuously changes clockwise or counterclockwise around these pinwheels. \cite{Yacoub10607} visualized the pinwheel structure in the human visual cortex, using high-field fMRI. The primary visual cortex is generally retinotopic \citep{Engel_97}, i.e. the orientation columns that are spatially close to each other in the primary visual cortex represent orientations that arrive spatially close to each other on the retina. This uniform, retinotopic cortical organization lends itself well to decoding analysis because there is a spatial correspondence between orientation and cortical activations that can be exploited by decoding models. Further, because simple cells are receptive to spatial frequencies, we can design stimuli, such as Gabor patches or gratings, that maximally activate simple and complex cells. 

\subsection*{Temporal Dependencies in Visual Perception}
There is a notable difference between our perception of the world and the signal that arrives at the photoreceptors and early visual areas. Real world visual input typically arrives in a discontinuous and noisy stream. The visual system has to piece together a continuous view of the world from this noisy input stream, so it uses certain bias mechanisms to smooth out our perception of the world. It is important to be able to both understand how perceptual mechanisms affect decoding algorithms and how we can model these perceptual mechanisms in decoding algorithms, as this will allow us to reconstruct a much better representation of a continuous and coherent perception of the world, rather than just reconstructing noisy inputs arriving from the LGN or primary visual cortex.

There are many perceptual mechanisms that the mind uses to create a more continuous and organized perception of the world. Adaptation is among the most studied of these mechanisms, and affects the perception of everything ranging from color \citep{webster_mollon_1997} to faces \citep{webster_macleod_2011}. Adaptation suggests that neurons become attuned to regularities in signals, saving energy by firing less when receiving regular signals. This adaptation mechanism relies on an understanding that the world generally remains constant, and it is more efficient for neurons to adapt to the world. However, over-adaptation can have a negative impact on visual perception, as a repulsion after-effect can result from long exposure to a single stimulus. In orientation perception, this manifests as the perceptual repulsion of a new orientation away from the adapted orientation \citep{He_sheng}.

\subsubsection*{Serial Dependence}
Another representative temporal dependency in visual perception is serial dependence, a perceptual mechanism that proposes that the present visual perception is systematically biased towards inputs from the recent past \citep{fischer_whitney_2014, Cicchini7867}. This is a reasonable mechanism, as the world generally remains constant from moment to moment, but the visual signal arriving at the retina is highly susceptible to changes in lighting, small head and eye movements, and noise. Therefore, serial dependence systemically biases new, noisy inputs towards a previous, consistent reconstruction of the world. \cite{fischer_whitney_2014} first showed that a serial dependence bias existed in the perception of orientation, finding that the perceived orientation of the current stimulus was biased up to 10 degrees toward the previous stimulus. This bias peaked when the previous stimulus was ~20-30 degrees away from the current stimulus in either direction, decaying as the orientation difference increased. This bias function is systemic and significant, showing that there is a scaled correction in orientation perception towards previously seen orientations. This shows that there is a serial dependence bias at one of the basic levels of visual perception, potentially affecting primary visual cortex neurons.

Serial dependence also occurs in larger ensembles of oriented Gabor patches \citep{Manassi}. \cite{Manassi} found that the perceived average orientation of a group of oriented Gabor patches was susceptible to the same serial dependence bias function found with single oriented gratings. This ensemble serial dependence suggests that serial dependence is also associated with scene processing, i.e. calculating average orientation. Calculating average orientation, or other statistical methods performed by the visual system, are important in determining the gist of a scene; for serial dependence to appear in these integrative "gist" calculations suggests that there is a systematic bias in scene perception. This would support the theory that serial dependence is used to smooth noisy visual input streams, as the smaller steps between scene gists would result in a more continuous perception. Further, the results of \cite{Manassi} confirm results from \cite{fischer_whitney_2014} that serial dependence effects are relatively long-lasting, up to 5-10 seconds.

\subsection*{Decoding and Encoding}
Decoding and encoding methods are essential to our understanding of the computational, or algorithmic, aspects of mind. Decoding methods attempt to find Pr(mental representation $|$ brain activity), i.e. finding the likelihood that a certain mental representation was present during some recorded brain activity, while encoding models find Pr(brain activity $|$ mental representation) \citep{king_2018}. Here, we were interested in decoding orientation from magnetoencephalography (MEG) signals, i.e. predicting what stimulus was shown to a subject given some MEG brain activity. This type of analysis is important because it can lead to sensitive and specific neural responses corresponding to a certain mental representation \citep{king_2018}. The neural mechanisms behind orientation in the primary visual cortex \citep{hubel_wiesel_1959} are well understood, but decoding analysis of orientation can still lead to a more specific understanding of the perceptual mechanisms, temporal dynamics, and frequency responses underlying orientation perception. In this research, we tested the limits of decoding with small, peripheral, randomly oriented gratings, and used decoding to generate insight into the temporal dynamics of current and previous orientation decoding.

\subsubsection*{Imaging Methods for Decoding}
Imaging techniques are central to decoding analysis; imaging measures the effects of processes in the brain, e.g. the blood-oxygen levels or synchronized electric field responses of neurons, which are then used to make informed guesses about those processes. However, all imaging techniques suffer some weakness, whether it be invasiveness, poor spatial locality, or poor temporal locality. For example, electroencephalography (EEG) is non-invasive and has excellent temporal locality, but has poor spatial locality; functional magnetic resonance imaging (fMRI) is similarly non-invasive, but it has excellent spatial locality and poor temporal locality; invasive methods like single or multi-unit recording cells or ECoG have great locality, but require surgery or animal testing to implement.

Initial successful attempts at decoding orientation were achieved with fMRI \citep{haynes_rees_2005, kamitani_tong_2005}. However, the resolution of fMRI (3mm) is lower than the sub-millimeter size of orientation columns in the visual cortex, calling into question whether or not fMRI is decoding orientation, or just discriminating between larger-scale activations related to the stimuli \citep{cichy_ramirez_pantazis_2015}. Further, fMRI measures BOLD response, i.e. an indirect measurement of brain activity based on the amount of oxygen delivered to neurons. This introduces both temporal latency and complex convolutions of hemodynamic responses into the decoding, making it harder to interpret decoding results \citep{cichy_ramirez_pantazis_2015}. Recent studies have also used MEG and EEG for decoding orientation, which could be a more direct measure of neuronal activity \citep{cichy_ramirez_pantazis_2015, pantazis_fang_qin_mohsenzadeh_li_cichy_2018, GARCIA2013515}, and achieved success at discriminating between small sets of large, oriented stimuli.

In this study, we primarily used MEG. MEG measures the weak magnetic fields that are generated by the electrical activity of neuron populations \citep{senior_russell_gazzaniga_2006}. Any electrical current will generate a perpendicular magnetic field, and neurons are no exception. The magnetic fields associated with neurons are particularly weak, as field strength falls off quadratically with distance, and the fields must penetrate through the skull. Thus, MEG primarily measures cortical activity, rather than deep brain activity, as magnetic fields associated with deep signals fall off too quickly to be measured. MEG uses incredibly powerful superconductors to pick on these magnetic fields, making the technology incredibly expensive, and very susceptible to noise. It is also clear that MEG does not react to single neuron action potentials, but instead reacts to synchronized firings of large populations of neurons. Thus, it is likely that MEG does not pick up the magnetic field associated with action potentials, which are relatively asynchronous, but the slower post-synaptic potentials associated with aligned populations of dendrites. From these aligned dendritic populations, MEG picks up three types of neuromagnetic fields: an anterior-posterior field, a left-right field, and a vertical field, pointing in or out from the skull.

MEG has similar properties to EEG; it is non-invasive, has good temporal locality, and poor spatial locality. MEG and EEG both suffer from the inverse problem; MEG and EEG electrodes are only able to pick up on electrical activity on the two-dimensional surface area of the scalp, and it is currently impossible to localize the origin of electromagnetic activity that could occur anywhere in the brain, especially after it passes through layers of bone and tissue. Because the spatial resolution of MEG is so poor, it seems unlikely that MEG decoding can directly measure activity at the resolution of cortical orientation columns. Nevertheless, \cite{cichy_ramirez_pantazis_2015} and \cite{ pantazis_fang_qin_mohsenzadeh_li_cichy_2018} suggest that MEG is sufficient for decoding orientation at these orientation columns. Further, to combat the poor spatial locality of MEG, structural MRI data can be used to provide information about how electrical signals would pass through the skull, allowing the signals to be localized with far greater accuracy. This process is known as source localization. We investigated the performance of source localization augmented decoding in comparison to MEG-only decoding.

MEG is able to measure the direct electromagnetic effects of orientation stimuli with great temporal locality, rather than the secondary BOLD effect found in fMRI. This temporal locality allows us to analyze the initial response to the orientation decoding as it happens, and investigate the MEG response as orientation information moves to higher processing levels. This is particularly useful for something like serial dependence analysis, where perceptual changes may occur at the millisecond level. 

\subsubsection*{Decoding Models}
There is a wealth of statistical models that can be used to decode orientation. Orientation decoding models have achieved success using vanilla statistical models, particularly with support vector machines (SVM) in fMRI \citep{mannion_mcdonald_clifford_2009} and MEG studies \citep{cichy_ramirez_pantazis_2015, pantazis_fang_qin_mohsenzadeh_li_cichy_2018}. These decoding models are well suited to experiments with few stimulus orientation possibilities. \cite{mannion_mcdonald_clifford_2009} used SVM to discriminate between two highly differentiable spiral orientation figures, oriented at +45 degrees and -45 degrees. Similarly, \cite{cichy_ramirez_pantazis_2015} used only two gratings at +45 and -45 degrees. \cite{pantazis_fang_qin_mohsenzadeh_li_cichy_2018} used 6 different stimuli, but only decoded the stimuli in pairs, effectively giving two stimuli to discriminate at a time. SVMs and other traditional decoding algorithms like logistic regression provide a great baseline to compare performance accuracy to, and generate proven results.

Decoding orientation is particularly tricky because of the circular nature of orientation. With orientation, a Gabor patch oriented at 3 degrees clockwise would look very similar to a Gabor patch oriented at 179 degrees clockwise, for example. This presents a challenge for the loss functions that are typically used in regression or classification problems, which would assign a high loss value to a prediction of 179 degrees when the actual orientation was 3 degrees, despite the angular similarity of the two orientations. This wouldn't be a problem for decoding the number of objects in a scene, for example, as predicting 179 objects in a scene with 3 objects in it should generate a high loss value. This problem also exists in decoding color, where a researcher might try to decode colors picked from a color wheel. The most natural solution to orientation decoding with a circular targets would be a circular regression, in which orientation outputs are modeled as the sine and cosine components of the orientation angle. However, this model can be very difficult to learn, especially for data with high noise and low expected decoding accuracy, like MEG data. Thus, a classification approach with continuous orientations binned into discrete classes can be a good substitute for circular regression, given small enough bins and enough data for each bin.

To solve this problem of circular decoding with a color stimulus, \cite{Brouwer09} applied an Inverted Encoding Model (IEM) to their fMRI data, which first transforms the stimulus orientations into a cosine basis set. The model then performs an encoding step, to predict the BOLD response for the stimulus orientations. A following decoding step generates activations corresponding to each potential orientation that can be decoded. The IEM has also been successfully used in EEG studies to decode orientation \citep{GARCIA2013515, sprague_serences_2013, sprague_saproo_serences_2015}. Because the IEM gives channel responses as an output rather than orientation predictions, any bias in channel response according to previous stimuli will be apparent. This may be useful for finding a serial dependence effect on decoding, as channel responses of orientations for the current stimulus may be biased by the relative position of the previous orientation.

\end{document}
\documentclass[../main.tex]{subfiles}

\begin{document}
Detecting the orientation of contrast edges is fundamental to visual perception in the primary visual cortex \citep{hubel_wiesel_1959, hubel_wiesel_1968}. In the past twenty years, research has shown that the orientation of a stimulus can be decoded from MEG and fMRI \citep{mannion_mcdonald_clifford_2009, cichy_ramirez_pantazis_2015}. However, recent experiments in visual serial dependence have shown that the perception of an oriented stimulus is often different from the actual stimulus \citep{fischer_whitney_2014}. Visual serial dependence suggests that the orientation perception of the current stimulus is biased towards the orientation of the previous stimulus. To what extent are orientation decoding models affected by the perception of orientation? Here, we investigated the impact of serial dependence on orientation decoding with MEG.

\subsection{Orientation}
Orientation is a well understood mechanism in the visual cortex, thanks largely to the works of Hubel and Wiesel. These mechanisms, which I will outline here, make orientation a reasonable candidate for decoding. Hubel and Wiesel first discovered cells in the visual cortex that were sensitive to orientation in 1958, when measuring the excitation of neurons in the cat primary visual cortex \citep{hubel_wiesel_1959}. \cite{hubel_wiesel_1962} then revealed the existence of simple and complex receptive fields in the cat visual cortex, both maximally sensitive to a particular orientation. Simple cells have very narrow excitatory receptive fields in which they respond to a single orientation at a single spatial location. These excitatory regions are surrounded by inhibitory regions, which generate inhibitory responses when aligned with the correct orientation. Complex cells have much wider excitatory receptive fields (i.e. they are spacially invariant), as they take in inputs from multiple simple cells tuned to a certain orientation in a spatial region. \cite{hubel_wiesel_1968} further revealed the existence of slabs in the primary visual cortex of a macaque and spider monkey that were made up of these simple and complex cells, each tuned to a small range of orientations. Later work revealed that simple cells were not bar detectors, as Hubel and Weisel supposed, but spatial frequency detectors \citep{DEVALOIS1982545, devalois_1978}. 

\cite{Yacoub10607} later revealed the organization of these orientation columns in the human visual cortex to be in a pinwheel structure. Particularly, orientations columns are organized around loci called "pinwheels", and orientations increase clockwise or counterclockwise around these pinwheels. Further, the primary visual cortex is generally retinotopic \cite{Engel_97}, i.e. the orientation columns that are spatially close to each other in the primary visual cortex represent orientations that arrive spatially close to each other on the retina. This uniform, retinotopic cortical organization lends itself well to decoding analysis because there is a spatial correspondence between orientation and cortical activations that can be exploited by decoding models. Further, because simple cells are receptive to spatial frequencies, we can design stimuli, such as Gabor patches or gratings, that maximally activate simple and complex cells. 

\subsection{Serial Dependence}
There is a notable difference between our perception of the world and the signal that arrives at the photoreceptors and early visual areas. In a lab setting, stimuli typically have a clean, uniform design that is atypical of real-world conditions. For example, this experiment used oriented Gabor patches, which are not typically found outside of psychology experiments. However, real world visual input typically arrives in a discontinuous and noisy stream. The visual system has to piece together a continuous view of the world from this noisy input stream, so it uses certain bias mechanisms to smooth out our perception of the world. It is important to be able to both understand how perceptual mechanisms affect decoding algorithms and how we can model these perceptual mechanisms in decoding algorithms, as this will allow us to reconstruct a much better representation of a continuous perception of the world, rather than just reconstructing noisy inputs arriving from the LGN or primary visual cortex.

There are many perceptual mechanisms that the mind uses to create a more continuous and organized perception of the world, such as adaptations to color \citep{webster_mollon_1997} and faces \citep{webster_macleod_2011}. This paper focuses on visual serial dependence, which proposes that the present visual perception is systematically biased towards inputs from the recent past \citep{fischer_whitney_2014, Cicchini7867}. This is a reasonable mechanism, as the world generally remains constant from moment to moment, but the visual signal arriving at the retina is highly susceptible to changes in lighting, small head and eye movements, and noise. Therefore, serial dependence systemically biases new, noisy inputs towards a previous, consistent reconstruction of the world. \cite{fischer_whitney_2014} first showed that a serial dependence bias existed in the perception of oriented gratings, finding that perceived orientation of the current stimulus was biased up to 10 degrees toward the previous stimulus. This bias peaked when the previous stimulus was ~20-30 degrees away from the current stimulus in either direction, decaying as the orientation difference approached 0 degrees or 90 degrees. This bias function is systemic and significant, showing that there is a scaled correction in perception toward the previous stimulus. This shows that there is a serial dependence bias at one of the basic levels of visual perception, potentially affecting primary visual cortex neurons. \cite{Cicchini7867} showed that this serial dependence effect persists to numerosity, where the perception of the number of objects in a scene is dependent on the number of objects in the previous scene displayed.

Serial Dependence also occurs in larger ensembles of oriented Gabor patches \citep{Manassi}. \cite{Manassi} found that the perceived average orientation of a group of oriented Gabor patches was susceptible to the same serial dependence bias function found with single oriented gratings, though with a smaller peak bias of about 2 degrees. This ensemble serial dependence suggests that serial dependence is also associated with scene processing, i.e. calculating average orientation. Calculating average orientation, or other statistical methods performed by the visual system, are important in determining the gist of a scene; for serial dependence to appear in these integrative "gist" calculations suggests that there is a systematic bias in scene perception. This would support the theory that serial dependence is used to smooth noisy visual input streams, as the smaller steps between scene gists would result in a more continuous perception. Further, the results of \cite{Manassi} also show that serial dependence effects are relatively long-lasting, up to 5-10 seconds.

\cite{KIYONAGA2017493} summarizes the breadth of serial dependence effects found in visual perception. Particularly, the same serial dependence effects are noticeable in face perception \citep{liberman_2014}, suggesting that higher-level features are affected by serial dependence bias. In this study, a set of faces was created by interpolating facial features between a small set of faces. Participants were asked to morph a face towards their perception of a stimulus face shown, and it was found that this morph would be biased toward the previous face shown. \cite{KIYONAGA2017493} also noted the parallels between working memory serial dependence and visual serial dependence. These parallels highlight potential neural mechanisms behind serial dependence, such as persisting synaptic traces from previous orientations or active signals fired from higher cortical areas that induce bias. Currently, the exact neural mechanisms behind serial dependence are unknown.

Serial Dependence has systemic effects on perception at multiple levels of visual perception. Thus, if serial dependence has an effect on orientation decoding, these effects may apply to not just orientation decoding, but face decoding, numerosity decoding, or color decoding. There are other perceptual adjustments that may effect orientation decoding, but we focused on serial dependence here because of the particularly noticeable affects of serial dependence on orientation perception, and because it is relatively easy to replicate these serial dependence effects in experiments.

\subsection{Decoding and Encoding}
Decoding and encoding methods are essential to our understanding of the computational, or algorithmic, aspects of mind. Decoding methods attempt to find Pr(mental representation | brain activity), i.e. finding the likelihood that a certain mental representation was present during some recorded brain activity, while encoding models find Pr(brain activity | mental representation) \citep{king_2018}. Here, we were interested in decoding orientation from MEG, i.e. predicting what stimulus was shown to a subject given some MEG brain activity. This type of analysis is important because it can lead to sensitive and specific neural responses corresponding to a certain mental representation \citep{king_2018}. The neural mechanisms behind orientation in the primary visual cortex \citep{hubel_wiesel_1959} are well understood, but decoding analysis of orientation can still lead to understanding of perceptual mechanisms, as we investigated here, or to a deeper understanding of the temporal dynamics and frequency responses of orientation processing, as in \cite{GARCIA2013515}. In this research, we tested the limits of decoding with small, peripheral, randomly oriented gratings, and used decoding to generate insight into visual serial dependence.

\subsubsection{Imaging Methods for Decoding}
Imaging techniques are central to decoding analysis; imaging measures the effects of processes in the brain, e.g. the blood-oxygen levels or synchronized electric field responses of neurons, which are then used to make informed guesses about those processes. However, all imaging techniques suffer some weakness, whether it be invasiveness, poor spatial locality, or poor temporal locality. For example, electroencephalography (EEG) is non-invasive and has excellent temporal locality, but has poor spatial locality; functional magnetic resonance imaging (fMRI) is similarly non-invasive, but it has excellent spatial locality and poor temporal locality; invasive methods like single or multi-unit recording cells or eCoG have great locality, but require surgery or animal testing to implement.

Initial successful attempts at decoding orientation were achieved with fMRI \citep{haynes_rees_2005, kamitani_tong_2005}. However, the resolution of fMRI (3mm) is lower than the sub-millimeter size of orientation columns in the visual cortex, calling into question whether or not fMRI is decoding orientation, or just discriminating between larger-scale activations related to the stimuli \citep{cichy_ramirez_pantazis_2015}. Further, fMRI measures BOLD response, i.e. an indirect measurement of brain activity based on the amount of oxygen delivered to neurons. This introduces both temporal latency and complex BOLD convolutions into the decoding, making it harder to interpret decoding results \citep{cichy_ramirez_pantazis_2015}. Thus, studies have moved towards using MEG and EEG for decoding orientation, which is a direct measure of brain activity \citep{cichy_ramirez_pantazis_2015, pantazis_fang_qin_mohsenzadeh_li_cichy_2018, GARCIA2013515}, and achieved success at discriminating between small sets of large, oriented stimuli.

In this study, we primarily used magnetoencephalography (MEG). MEG measures the weak magnetic fields that are generated by the electrical activity of neuron populations \citep{senior_russell_gazzaniga_2006}. Any electrical current will generate a perpendicular magnetic field, and neurons are no exception. The magnetic fields associated with neurons are particularly weak, as field strength falls off quadratically with distance, and the fields must penetrate through the skull. Thus, MEG primarily measures cortical activity, rather than deep brain activity, as magnetic fields associated with deep signals fall off too quickly to be measured. MEG uses incredibly powerful superconductors to pick on these magnetic fields, making the technology incredibly expensive, and very susceptible to noise. It is also clear that MEG does not react to single neuron action potentials, but instead reacts to synchronized firings of large populations of neurons. Thus, it is likely that MEG does not pick up the magnetic field associated with action potentials, which are relatively asynchronous, but the slower post-synaptic potentials associated with aligned populations of dendrites. From these aligned dendritic populations, MEG picks up three types of neuromagnetic fields: an anterior-posterior field, a left-right field, and a vertical field, pointing in or out from the skull.

MEG has similar properties to EEG; it is non-invasive, has good temporal locality, and poor spatial locality. MEG and EEG both suffer from the inverse problem; MEG and EEG electrodes are only able to pick up on electrical activity on the two-dimensional surface area of the scalp, and it is currently impossible to localize the origin of electromagnetic activity that could occur anywhere in the brain, especially after it passes through layers of bone and tissue. To combat this issue, structural MRI data can be used to provide information about how electrical signals would pass through the skull, allowing the signals to be localized with far greater accuracy. This process is known as source localization.

MEG is able to measure the direct electromagnetic effects of orientation stimuli with great temporal locality, rather than the secondary BOLD effect found in fMRI. This temporal locality allows to analyze the initial response to the orientation decoding as it happens, and investigate the MEG response as orientation analysis moves to higher processing levels. This is particularly useful for serial dependence analysis, where perceptual changes may occur at the millisecond level. 

However, there are some challenges with MEG decoding. Because the spatial resolution of MEG is so poor, it seems unlikely that MEG decoding can directly measure activity at the resolution of cortical orientation columns. Also, it is hard to make assumptions about the spatial locality of a signal, as MEG signal pass through the scalp. Nevertheless, \cite{cichy_ramirez_pantazis_2015, pantazis_fang_qin_mohsenzadeh_li_cichy_2018} suggest that MEG is sufficient for decoding orientation at these orientation columns. Further, we investigated whether source localization with MRI could boost the spatial resolution of MEG. In addition to the resolution challenge, MEG is also susceptible to the same stimulus-based confounds as fMRI. For example, an attempted to decode two large, Gabor patch stimuli may not pick up on the orientation differences between the two stimuli, but the large-scale physical differences in appearance. To counteract this potential confound, we used a large variety of small, peripheral orientations. 

\subsubsection{Decoding and Encoding Models}
There is a wealth of decoding and encoding algorithms that can be used, as discussed here. Orientation decoding models have achieved success using vanilla statistical models, particularly with support vector machines (SVM) in fMRI \citep{mannion_mcdonald_clifford_2009} and MEG studies \citep{cichy_ramirez_pantazis_2015, pantazis_fang_qin_mohsenzadeh_li_cichy_2018}. These decoding models are well suited to experiments with few stimulus orientation possibilities. \cite{mannion_mcdonald_clifford_2009} used SVM to discriminate between two highly differentiable spiral orientation figures, oriented at +45 degrees and -45 degrees. Similarly, \cite{cichy_ramirez_pantazis_2015} use only two oriented gratings at -45 and +45 degrees. \cite{pantazis_fang_qin_mohsenzadeh_li_cichy_2018} use 6 different stimuli, but only decode the stimuli in pairs, effectively giving two stimuli to discriminate at a time. SVMs and other traditional decoding algorithms like logistic regression provide a great baseline to compare performance accuracy to, and generate proven results.

Neural networks are not used in decoding as much as SVMs, as they can be prone to overfitting data and can be less interpretable than SVMs or logistic regression models. However, deep learning neural networks have shown promise in learning multiple levels of abstraction in complex data \cite{lecun_bengio_hinton_2015}, meaning deep neural networks could be well suited to learning patterns in MEG activity. Convolutional neural network models have shown particular promise in decoding activity from MEG \citep{seeliger_2018}. These models are more experimental and have a high potential for overfitting, but they could produce promising decoding results for larger sets of orientation stimuli, as they are well-suited for learning abstractions of data. 

Decoding orientation is particularly tricky because of the circular nature of orientation. With orientation, a Gabor patch oriented at 3 degrees clockwise would look very similar to a Gabor patch oriented at 179 degrees clockwise, for example. In fact, these orientations would look more similar than an orientations of 3 degrees clockwise. This presents a challenge for the loss functions that are typically used in regression or classification problems, which would assign a high loss value to a prediction of 179 degrees when the actual orientation was 3 degrees, despite the two orientations being nearly identical physically. This wouldn't be a problem for decoding the number of objects in a scene, for example, as predicting 179 objects in a scene with 3 objects in it should generate a high loss value. This problem also exists in the decoding of color, where a researcher might try to decode colors picked from a color wheel. 

To solve this problem of circular decoding with a color stimulus, \cite{Brouwer09} used an Inverted Encoding Model (IEM), which first transforms the stimulus orientations into a cosine basis set. The model then performs an encoding step, to predict the MEG response for the stimulus orientations, and then performs a decoding step, to generate activations corresponding to each potential orientation that can be decoded. The IEM was successfully used in \cite{GARCIA2013515, sprague_serences_2013, sprague_saproo_serences_2015} to decode orientation from EEG. Because the inverted encoding model gives channel responses as an output rather than orientation predictions, any bias in channel response according to previous stimuli will be apparent. This is useful for finding any serial dependence effect on decoding, as channel responses of orientations for the current stimulus may be biased towards channel responses for the previous orientation.

\end{document}